- [Introduction](#introduction)
  - [Focus of the course](#focus-of-the-course)
  - [Abstract Data Type vs Data Structure](#abstract-data-type-vs-data-structure)
    - [Abstract Data Type](#abstract-data-type)
    - [Data Structure](#data-structure)
    - [Examples](#examples)
- [Analysis of Data Structures](#analysis-of-data-structures)
  - [Worst-case](#worst-case)
  - [Average-case](#average-case)
  - [Amortized Analysis](#amortized-analysis)
    - [Amortized Analysis with Potential Function Method](#amortized-analysis-with-potential-function-method)
- [Array](#array)
  - [Abstract Data Type](#abstract-data-type-1)
    - [Data](#data)
    - [Operations](#operations)
- [Array List - Dynamic Arrays](#array-list---dynamic-arrays)
  - [Abstract Data Type](#abstract-data-type-2)
    - [Data](#data-1)
    - [Operations](#operations-1)
  - [Implementation](#implementation)
    - [Data](#data-2)
    - [Operation \& Amortized Analysis](#operation--amortized-analysis)
      - [Increment](#increment)
      - [Decrement](#decrement)
- [Stack](#stack)
  - [Abstract Data Type](#abstract-data-type-3)
    - [Data](#data-3)
    - [Operations](#operations-2)
  - [Implementation](#implementation-1)
- [FIFO Queue](#fifo-queue)
  - [Abstract Data Type](#abstract-data-type-4)
    - [Data](#data-4)
    - [Operations](#operations-3)
- [Deque - Double-Ended Queue](#deque---double-ended-queue)
  - [Abstract Data Type](#abstract-data-type-5)
    - [Data](#data-5)
    - [Operations](#operations-4)
- [Dictionary Problem](#dictionary-problem)
  - [Abstract Data Type](#abstract-data-type-6)
    - [Data](#data-6)
    - [Operations](#operations-5)
- [Hashing](#hashing)
  - [Basics](#basics)
    - [Load Factor](#load-factor)
    - [Hash Function](#hash-function)
    - [Rehashing](#rehashing)
  - [Hash Collision](#hash-collision)
    - [Hash Chaining](#hash-chaining)
      - [Operations](#operations-6)
      - [Advantage](#advantage)
      - [Disadvantage](#disadvantage)
    - [Linear Probing](#linear-probing)
      - [Analysis](#analysis)
      - [Code](#code)
      - [Disadvantage](#disadvantage-1)
    - [Quadratic Probing](#quadratic-probing)
    - [Double Hashing](#double-hashing)
    - [Cuckoo Hashing](#cuckoo-hashing)
      - [Analysis](#analysis-1)
- [Priority Queue](#priority-queue)
- [Sets](#sets)
- [Binary Search Tree](#binary-search-tree)
- [Search](#search)
- [Tries](#tries)


# Introduction
## Focus of the course
Anlyze the performance of the algorithm implemented with given data structure.  
## Abstract Data Type vs Data Structure
### Abstract Data Type
Abstract data type defines the **logical** form of the data type. We care about the data type and operations about ADT.
### Data Structure
The data structure implements the **physical** form of the data type.  
### Examples
Dictionary
Abstract Data Type:  
- Data type: key-value pairs  
- Operations: 
  - Query: find value associated with a given key
  - Update: store value of a given key  

Data Structure:  
The actual implementation of the ADT above:  
- Hashing schemes
- Balanced binary search trees

# Analysis of Data Structures
## Worst-case
Restrictive time used for real-time response time analysis.
## Average-case
Expected time value, taking input probilities in to account. As we are making assumption about the probilities, average-case time can be inaccurate.
## Amortized Analysis
**Worst** case time for a **sequence** of operations.  
$$\text{Total Actual Time} \leq \text{Total Amortized Time}$$
Worst-case amortized time is the upper bound of worst-case actual time. [Proof see note 2-15](https://www.ics.uci.edu/~dillenco/compsci261p/notes/notes2-handout.pdf).  
### Amortized Analysis with Potential Function Method
1. Define a non-negative potential function $\Phi$, describing the states of the data structure. Initially $\Phi=0$
> Think potential function as the distance between current state of the data structure and the idea state. One analogy would be the gravitational potential energe.  

2. Define amortized time of an operation:
$$\text{amortized time} = \text{actual time} + C\times(\Phi_{new}-\Phi_{old})$$
> The amortized time equals actual time plus change of potential. If change of potential is positive, the data structure is further from its idea state, which is going to cost more time for future operations.  

> The potential is 0 when the data structure is initialized.  
> The potential of the data structure is non-negative(zero or positive).    
> The change of potential $\Delta\Phi=\Phi_{new}-\Phi{old}$ may be negative.
> The actual time of an operation is always positive.
> The amortized time of an operation may be negative, which will make it O(1).

# Array
## Abstract Data Type
### Data
Contiguous store of data items, with fixed length
### Operations
1. Create array of length n, 0-indexed by convention
2. Store a given value at a given index
3. Retrieve value stored at a given idex


# Array List - Dynamic Arrays
## Abstract Data Type
### Data
Continuous store of data items, with variable length. Combines the functionalities of arrays and linked lists.  
### Operations
1. Create a new ArrayList of length n
2. Return length of the current ArrayList
3. Store an item in given location index i
4. Reterieve the item stored in location index i
5. Increase the current length by 1
6. Decrease the current length by 1
## Implementation
Use fixed length array to implement ArrayList
### Data
Current number of elements (or length) L.  
Underlying array B, with $|B|\geq L$.
> $|B|$ denotes the length of array B.  

Keep $|B|/4 \leq L \leq |B|$, if smaller than $|B|/4$ shrink size to idea size, if larger than $|B|$ expand size to idea size.     
Ideal state $L = |B|/2$
### Operation & Amortized Analysis
Given that the ideal state of this data structure implementation is $L = |B|/2$, we can define the potential function
$$\Phi=|2L-|B||$$
#### Increment
Increase the length of ArrayList by 1, if L is too big that it exceeds $|B|$, reallocate underlying array.
```
L = L + 1
if L > sizeof(B):
  B_NEW = allocate new array of size 2*L
  copy B in to B_NEW
  set remaining location of B_NEW to null
  B = B_NEW
```
Amortized time for increment operation where B is resized:  
$\text{Potential Fucntion} \Phi=|2L-|B||$  
$\text{Amortized Time} = \text{Actual Time} + C\times \Delta\Phi$  
$\text{Actual Time} \leq c\times(L+1)$ for copying $L+1$ elements.  
$\Phi_{old}=|2L-|L||=L$  
$\Phi_{new}=|2L-|2L||=0$  
$\text{Amortized Time} \leq c\times(L+1) + c\times(\Phi_{new}-\Phi_{old})$  
$=c\times(L+1)+c\times(-L)=c=O(1)$  
#### Decrement
Decrease the length of ArrayList by 1, if L is smaller than $|B|/4$, resize the underlying array to $2L$.  
Amortized time for decrement operation where B is resized:  
$\text{Potential Fucntion} \Phi=|2L-|B||$  
$\text{Amortized Time} = \text{Actual Time} + C\times \Delta\Phi$  
$\text{Actual Time} \leq c\times(L-1)$ for copying $L-1$ elements.  
$\Phi_{old}=|2L-|4L||=2L$  
$\Phi_{new}=|2L-|2L||=0$  
$\text{Amortized Time} \leq c\times(L+1) + c\times(\Phi_{new}-\Phi_{old})$  
$=c\times(L+1)+c\times(0-2L)=-cL=O(1)$  
> As per lecture note, negative amortized time is valid, and quantity would be $O(1)$
```
L = L - 1
if 4*L < sizeof(B):
  B_NEW = allocate new array of size 2*L
  copy data, set other locations
  B = B_NEW
```

# Stack
## Abstract Data Type
### Data
Contiguous store of data items, with variable length and FILO/LIFO properties.
### Operations
1. Create an empty stack
2. Push: insert an item at the top of the stack
3. Pop: remove the item at the top of the stack
## Implementation
Stack can be implemented with ArrayList. When using implementing something with known data structure, we can use its amortized operation times as new base operation times.

# FIFO Queue
## Abstract Data Type
### Data
Contiguous store of data items, with variable length and FIFO properties.
### Operations
1. Create an empty queue
2. Enqueue: insert an item at the rear of the queue
3. Dequeue: Remove the item at the front of the queue

# Deque - Double-Ended Queue
## Abstract Data Type
### Data
Contiguous store of data items, with combined functionality of stack and queue.
### Operations
1. Create and empty deque
2. Insert an item at the front of the deque
3. Insert an item at the rear of the deque
4. Remove an item at the front of the deque
5. Remove an item at the rear of the deque

# Dictionary Problem
## Abstract Data Type
### Data
Collection of key-value pairs.  
Keys can be numbers, string, memory address, etc.  
Values can be basic data types or references.
### Operations
1. Search value associated with given key
2. Update value of given key, or add new pair if key not previously exist in the dictionary
3. Delete pair associated with given key

# Hashing
Suppose we have n key-value pairs, n may change as we perform set/delete operations.  
Maintain a hash table H of size N > n, N may require resizing as n changes.
## Basics
### Load Factor
Load factor is the number of elements in a hash table divided by the total number of table slots.  
$$\alpha=\frac{n}{N}$$
### Hash Function
Hash function h: $\text{keys}\rarr\text{indices in hash table}$
### Rehashing
If we need to resize H to accomodate more elements, we need choose a new hash function that map all possible key to new N indices.
## Hash Collision
Different hash key mapped to the same hash index value.  
Few strategies discussed in the lecture for dealing with hash collsions:
### Hash Chaining
Each cell of hash table H store a collection (as ArrayList or linked list) of key-value pairs.
#### Operations
Estimated time per operation = $O(1+\alpha)$.
> 1 comes from the inevitable hash opertion and collection lookup  
> The number of n-1 existing keys colliding with k is $(n-1)\times\frac{1}{N}$, assuming hash function generate N indices with the same likelihood.  
1. Search(key): first find the collection in the hash table, then scan through the collection, looking for the pair corresponds to given key.
2. Set(key, value): Update pair or add new pair to the collection.
3. Delete(key): delete the pair in the collection.
#### Advantage
Hash chaining is a simple solution that works.  
#### Disadvantage
Extra space for storage and slower access time.
### Linear Probing
Each cell of hash table H store one key-value pair.  
Try to store (k,v) in index position h(k), if full try h(k)+1, h(k)+2, so forth and wrap around modulo N.
#### Analysis
Omit the proof, the expect search time of hash table with linear probing is $O(1)$.  
Expected time for successful search
$$O\left(1+\frac{1}{(1-\alpha)}\right)$$
Expected time for unsuccessful search
$$O\left(1+\frac{1}{(1-\alpha)^2}\right)$$
#### Code
```
def search(k):
  i = h(k)
  while H[i] is non-empty and key != k:
    i = (i+1)%N
  // key == k
  if H[i] is non-empty:
    return H[i].value
  else:
    exception
```
```
def set(k,v):
  i = h(k)
  while H[i] is non-empty and key != k:
    i = (i+1)%N
  H[i] = v
```
A simple solution for deletion would be mark the deleted position with a flag, indicating the value is nolonger available.  
The following code is for moving probed elements to the front.
```
def delete(k):
  i = h(k)
  while H[i] is non-empty and key != k:
    i = (i+1)%N
  if H[i] is empty:
    exception
  j = (i+1)%N
  while H[j] is non-empty:
    if h(H[j].key) not in circular range [i+1, j]:
      move H[j] to H[i]
      i = j
    j = j + 1
```
i points to available empty spot in the left side  
j scan through current chunck of elements      
#### Disadvantage
Performance degrades as load factor $\alpha=\frac{n}{N}$ gets close to 1.
### Quadratic Probing
Instead of looking for next one slot, look for $h(k)+1$, $h(k)+4$, $h(k)+9$, etc.
### Double Hashing
User a secondary hash function $h_2(k)$, try $h(k)+h_2(k)$, $h(k)+2\times h_2(k)$, $h(k)+3\times h_2(k)$, etc. 
### Cuckoo Hashing
Two hash tables: $H_0$, $H_1$  
Two hash functions: $h_0$, $h_1$  
Search(k): Look in both places $H_0[h_0(k)]$, $H_1[h_1(k)]$  
Set(k,v): 
#### Analysis
Guranteed $O(1)$ search time, at the cost of slower set operation.
# Priority Queue

# Sets

# Binary Search Tree

# Search

# Tries
