- [CS250P Computer System Architecture](#cs250p-computer-system-architecture)
  - [Grading](#grading)
  - [Motivation](#motivation)
    - [End of Moore's Law](#end-of-moores-law)
    - [End of Dennard Scaling](#end-of-dennard-scaling)
    - [Solution](#solution)
  - [Hardware - Software Interface](#hardware---software-interface)
    - [Concept of Abstraction](#concept-of-abstraction)
    - [ISA - Instruction Set Architecture](#isa---instruction-set-architecture)
      - [Definition](#definition)
      - [Where is ISA](#where-is-isa)
      - [Types of ISA](#types-of-isa)
    - [Performance Measurements](#performance-measurements)
      - [CPU Clock](#cpu-clock)
      - [CPU Time](#cpu-time)
      - [Instruction Count](#instruction-count)
      - [Cycle per Instruction - CPI](#cycle-per-instruction---cpi)
      - [Conclusion](#conclusion)
  - [ISA Classification](#isa-classification)
    - [RISC - Reduced Instruction Set Computer](#risc---reduced-instruction-set-computer)
    - [CISC - Complex Instruction Set Computer](#cisc---complex-instruction-set-computer)
  - [RISC-V](#risc-v)
  - [x86](#x86)
  - [RISC-V Assembly & x86 Assembly](#risc-v-assembly--x86-assembly)
  - [Digital Circuits](#digital-circuits)
    - [Why Digital Over Analog](#why-digital-over-analog)
      - [Disadvantage of Analog Computer](#disadvantage-of-analog-computer)
      - [Advantage of Digital Computer](#advantage-of-digital-computer)
    - [Types of Digital Circuits](#types-of-digital-circuits)
    - [Combinational Circuit](#combinational-circuit)
      - [Timing Specifications of Combinational Circuits](#timing-specifications-of-combinational-circuits)
      - [Propagation Delay of Combinational Circuits](#propagation-delay-of-combinational-circuits)
      - [Contamination Delay of Combinational Circuits](#contamination-delay-of-combinational-circuits)
    - [Sequential Circuit](#sequential-circuit)
  - [Pipeline](#pipeline)
    - [Improve Combinational Circuit](#improve-combinational-circuit)
      - [Problem With Combinational Circuit Without Pipeline](#problem-with-combinational-circuit-without-pipeline)
      - [Goal](#goal)
      - [Measurement of System Performance](#measurement-of-system-performance)
    - [Solution - Pipeline](#solution---pipeline)
      - [Definition](#definition-1)
      - [Latency & Throughput in K-Stage Pipeline](#latency--throughput-in-k-stage-pipeline)
    - [Example Pipelining Question](#example-pipelining-question)
      - [Latency and Throughput without Pipelining](#latency-and-throughput-without-pipelining)
      - [Latency with 4-Stage Pipeline](#latency-with-4-stage-pipeline)
    - [RISC Pipeline](#risc-pipeline)
      - [Von Neumann Model](#von-neumann-model)
      - [Five Stage Pipeline](#five-stage-pipeline)
      - [3-Stage Pipeline Analysis](#3-stage-pipeline-analysis)
      - [Why 5-Stage? Ideally Balanced Pipeline](#why-5-stage-ideally-balanced-pipeline)
    - [Pipeline Hazard](#pipeline-hazard)
    - [Branch Prediction](#branch-prediction)
    - [Superscale](#superscale)
  - [Memory System and Cache](#memory-system-and-cache)

# CS250P Computer System Architecture
## Grading
1. Homework 50%
2. Mid term 25%
3. Final 25%
## Motivation
```
Moore's Law
The number of transistors on an integrated circuit will double every two years.

   +

Dennard Scaling
As transistors get smaller, their power density stays constant.
Length▼ Voltage▼ Current▼

   │
   ▼

The tech journalists' narrative:
"Hardware performace doubles each year."
```
### End of Moore's Law
Due to physical limitations and rising costs, the transistors can't be smaller.
### End of Dennard Scaling
$$
power \propto leakage_{(static)} + \alpha * {CFV^2}_{(dynamic)}\\ 
\alpha = constant\\ 
C = Capacitance\\ 
F = Frequency\\ 
V = Voltage\\ 
$$
> $\propto$: proportional to  

Idealy, as the size of transistor shrinks, voltage was reduced. So we can affort to operate the chip at higher frequency at the same power.  
However leakage power (static baseline power) is proportional to ${1}\over{voltage}$.  
Therefore power density of chip is increased as transistors get smaller.
### Solution
1. Multicore + Multithread - has limitations too!
2. Larger Chip - M1 Chip
3. Task specific chips - i.e. video encode/decode 

## Hardware - Software Interface
### Concept of Abstraction
Hide low level detail to deal with more complicated stuff.  
Examples:
1. API - Application Programming Interface
2. System Calls
3. ABI - Application Binary Interface
4. **ISA** - Instruction Set Architecture

### ISA - Instruction Set Architecture
#### Definition  
The abstraction between software and hardware (Hardware/Software Interface).  
#### Where is ISA
```
High-level Language        a = a + 1

     │
     │  compiler
     ▼

Assembly Language          add x6,1,x6

     │
     │  assembler
     ▼

Hardware Representation    000101011 <-ISA-> Hardware
```
#### Types of ISA
1. RISC - Reduceed Instruction Set Computer
2. CISC - Complex Instruction Set Computer  

### Performance Measurements
Define $\text{Performance} = \frac{1}{\text{Execution Time}}$, the measurements of performance is corelated to the measurements of execution time. We will ignore I/O time, idle time and focus on **CPU time**.  
#### CPU Clock
The constant-rate clock governing digital hardwares.
* Clock Cycle Time(Clock Period): Duration of one clock cycle. Unit nanoseconds. 
* Clock Frequency(Clock Rate): Cycles per second. Unit Giga Hertz.
$$\text{Period} = \frac{1}{\text{Frequency}}$$
#### CPU Time
$$\text{CPU Time} = \text{\#Cycles} \times \text{Period} = \frac{\text{\#Cycles}}{\text{Frequency}} $$
To improve CPU time (performance)
1. Reduce number of cycles
2. Reduce cycle time by increasing frequency
#### Instruction Count
Total number of instructions of a program, determined by program, ISA and compiler.
#### Cycle per Instruction - CPI
Number of clock cycle per instruction is determined by CPU hardware and the type of instruction. For RISC CPI is constant and for CISC we are talking about **average** CPI.  
$$\text{\#Cycles} = \text{\#Instruction} \times \text{Cycle per Instruction}$$
#### Conclusion
$$\text{CPU Time} = \frac{\text{\#Instruction} \times \text{CPI}}{\text{Frequency}} $$
Factors that influence performance:
1. Algorithm: instruction count
2. Programming Language: instruction count
3. Compiler: instruction count & CPI
4. Instruction Set Architecture: instruction count & CPI & clock speed  

To improve CPU time, as the measurement of performance, the ISA design needs to feature:
1. Low instruction count
2. Low CPI
3. High frequency (clock speed)

## ISA Classification
### RISC - Reduced Instruction Set Computer
* Small number of general instructions
* Computation performed in register
* Memory acceess is different instructions
* Fixed length instruction encoding
* Complex instruction was composed of general instructions  

Examples: RISC-V, ARM(Advanced RISC Machine)
### CISC - Complex Instruction Set Computer
* Large number of complex instructions
* Various memory and register modes per instruction
* Varible length instruction encoding  

Examples: Intel x86

## RISC-V
[RISC-V](https://www.ics.uci.edu/~swjun/courses/2022F-CS250P/materials/lec3%20-%20RISC-V,%20x86%20Assembly.pdf)
## x86
[x86](https://www.ics.uci.edu/~swjun/courses/2022F-CS250P/materials/lec3%20-%20RISC-V,%20x86%20Assembly.pdf)
## RISC-V Assembly & x86 Assembly
[ISA Encoding Comparison(Red Commented Part)](https://www.ics.uci.edu/~swjun/courses/2022F-CS250P/materials/lec3.5%20-%20RISC-V,%20x86%20Assembly%20Encoding.pdf)

## Digital Circuits
### Why Digital Over Analog
#### Disadvantage of Analog Computer
Analog computers are susceptible to noise, distortion, and interference. Noise is accumulated at each component.  
#### Advantage of Digital Computer
1. Noise is cancelled at each digital component, as each digital component can generate a new & cleaner signal.
2. Complex designs can be achieved on the abstraction of digital behavior.


### Types of Digital Circuits
1. Combinational - output is function of current input
2. Sequential - output depends on the sequence of past inputs

### Combinational Circuit
Components:
1. Input
2. Output
3. Function Specifications
4. Timing Specifications

#### Timing Specifications of Combinational Circuits
1. Propagation Delay $t_{PD}$    
   - The **maximum** time delay from **valid** input to **valid** output.  
   - Restrict of how fast an input can be comsumed. The input signal must be held long enough for generating an valid output.
2. Contamination Delay $t_{CD}$  
   - The **minimum** time delay from when input **starts** to change to output **starts** to change.  
   - Within contamination delay time, change to input will not affect output signal.  

#### Propagation Delay of Combinational Circuits
Overall delay of a circuit is determined by **critical path**, which is the longest possible path of a circuit. Longer delay will limit the clock speed (longer period & lower frequency).
$$\text{Overall } t_{PD} = \sum_{i=1}^{n} t_{PD_i} \text{  for each component in critical path}$$
#### Contamination Delay of Combinational Circuits
Determined by shortest path in a circuit.
### Sequential Circuit
Rater trivial.

## Pipeline
### Improve Combinational Circuit
#### Problem With Combinational Circuit Without Pipeline
Complex Logic ─► Long Critical Path ─► High Propagation Delay ─► Reduced Clock Speed  
Inputs and outputs of each gate component have to be held until the final output is stable.
#### Goal
Run complex processor at higher clock speed, and achieve higher performance.

#### Measurement of System Performance
1. Latency - The time delay between an entered input and its associated output.
2. Throughtput - The rate at which input or output is processed.  

### Solution - Pipeline
#### Definition
1. **K-Stage pipeline** is an acyclic circuit having exactly k **registers** on **every** input/ouput path.  
2. Each pipeline stage needs a register on the output.  
3. The clock period $t_{CLK}$ only needs to cover the **longest** propagation time from previous stage register to the next stage register.
#### Latency & Throughput in K-Stage Pipeline
1. $\text{Latency} = K \times t_{CLK}$
2. $\text{Throughtput} = \frac{1}{t_{CLK}}$  
> #### Understand the Advantage of Pipeline
> The clock period only needs to over the propagation delay between two registers from two adjacent stages, instead of the entire critical path. Therefore, we can shorten the clock period (higher clock rate), which increases throughput at cost of latency (not by much).

> [Pipelining Methodology Page 10](https://www.ics.uci.edu/~swjun/courses/2022F-CS250P/materials/lec5%20-%20The%20processor.pdf)  
> [Number of Stages Balancing Between L and T Page 11](https://www.ics.uci.edu/~swjun/courses/2022F-CS250P/materials/lec5%20-%20The%20processor.pdf)  
> [IMPORTANT Exam Question Page 13](https://www.ics.uci.edu/~swjun/courses/2022F-CS250P/materials/lec5%20-%20The%20processor.pdf)  

### Example Pipelining Question
Each module in the diagram is labeled with its latency.  
Request: Pipe this circuit to maximize throught put and minimize latency.
```
     ┌─┐    ┌─┐    ┌─┐    ┌─┐    ┌─┐
────►│2├───►│3├───►│4├───►│2├───►│1├───►
     └┬┘    └─┘    └─┘    └─┘    └─┘
      │             ▲
      │     ┌─┐     │
      └────►│4├─────┘
            └─┘
```

#### Latency and Throughput without Pipelining
0-Stage or 1-Stage pipeline, the length of critical path is going down at first branch.
$$t_{PD} = 13$$
$$\text{Throughput} = \frac{1}{13}$$
$$\text{Latency} = 13$$
#### Latency with 4-Stage Pipeline
How do we come to the pipeline staging design? By instinction?
```
         1      2      3             4

         │      │      │             │
     ┌─┐ │  ┌─┐ │  ┌─┐ │  ┌─┐    ┌─┐ │
────►│2├─┼─►│3├─┼─►│4├─┼─►│2├───►│1├─┼─►
     └┬┘ │  └─┘ │  └─┘ │  └─┘    └─┘ │
      │  │      │   ▲  │             │
      │  │  ┌─┐ │   │  │             │
      └──┼─►│4├─┼───┘  │             │
         │  └─┘ │      │             │
         │      │      │             │
```
The longest register to register propagation delay is 4 time unit.
$$t_{CLK} = 4$$
$$\text{Throughput} = \frac{1}{t_{CLK}} = \frac{1}{4}$$
$$\text{Latency} = K\times t_{CLK} = 4\times 4 = 16$$  
### RISC Pipeline
#### Von Neumann Model
**Data** and **instruction** stored in the same main memory. Treating programs as data.  
**CPU** fetches, interprets, and executes intructions from **memory**.
#### Five Stage Pipeline
```
   ┌───────┐    ┌────────┐   ┌─────────┐   ┌────────┐   ┌────────────┐
   │       │    │        │   │         │   │        │   │            │
┌─►│ Fetch ├───►│ Decode ├──►│ Execute ├──►│ Memory ├──►│ Write Back ├─┐
│  │       │    │        │   │         │   │        │   │            │ │
│  └───────┘    └────────┘   └─────────┘   └────────┘   └────────────┘ │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```
1. Fetch - Get instruction
2. Decode - Instruction decode & register read
3. Execute - Execute operation or calculate address
4. Memory Access - Request memory read or write
5. Write Back - Write execution result or memeory access result back to register  
#### 3-Stage Pipeline Analysis
Memeory is not part of combinational circuit, memory accesses should be separate stages. 3-Stage is the most basic staging.  
1. Fetch - Fetch instruction from memory
2. Execute - Decode, Execute(ALU), Register File Access, Memory **Request**
3. Write Back - Memory Read (Response to Request)

The second stage is disproportionately long. The clock period needs to be long enough to cover the propagation delay of second stage. Some CPU time in first and third stage is idle.  
```
          ┌───┐----┌───────┬───┐----┐
instr. 1  │ F │    │  Exe  │ W │    |
          └───┘----└───────┴───┘----┘

                   ┌───┐----┌───────┬───┐----┐
instr. 2           │ F │    │  Exe  │ W │    |
                   └───┘----└───────┴───┘----┘
```
#### Why 5-Stage? Ideally Balanced Pipeline
```
           ┌─────┬─────┬─────┬─────┬─────┐
instr. 1   │ Fet │ Dcd │ Exe │ Mem │ Wrt │
           └─────┴─────┴─────┴─────┴─────┘

                 ┌─────┬─────┬─────┬─────┬─────┐
instr. 2         │ Fet │ Dcd │ Exe │ Mem │ Wrt │
                 └─────┴─────┴─────┴─────┴─────┘

                       ┌─────┬─────┬─────┬─────┬─────┐
instr. 3               │ Fet │ Dcd │ Exe │ Mem │ Wrt │
                       └─────┴─────┴─────┴─────┴─────┘
```
Every stage have similar propagation delay and CPU is kept busy at each clock period.

### Pipeline Hazard
### Branch Prediction
### Superscale

## Memory System and Cache